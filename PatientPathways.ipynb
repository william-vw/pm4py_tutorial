{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (auxilliary function for printing markdown)\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'ArtificialPatientTreatment.csv'\n",
    "# row = event about performing *activity* at *timestamp* concerning *patient case*\n",
    "# (here, also incl. the *resource* involved; the consulting doctor)\n",
    "events = pd.read_csv(file)\n",
    "\n",
    "# also do some initial data prep\n",
    "events.columns = ['patient', 'action', 'resource', 'timestamp']\n",
    "events['timestamp'] = pd.to_datetime(events['timestamp'])\n",
    "events['action'] = events['action'].apply(lambda x: x.strip())\n",
    "\n",
    "# print out first few rows to get an idea of the data\n",
    "events.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} has {} rows and {} columns.'.format(file, events.shape[0], events.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - per case, get the start and end times\n",
    "\n",
    "# (start & end times of patient cases =  min. and max. value of all timestamps per patient, respectively)\n",
    "case_starts_ends = events.pivot_table(index='patient', aggfunc={'timestamp': ['min', 'max']})\n",
    "case_starts_ends = case_starts_ends.reset_index()\n",
    "case_starts_ends.columns = ['patient', 'caseend', 'casestart']\n",
    "# (add these new columns to event table)\n",
    "events = events.merge(case_starts_ends, on='patient')\n",
    "\n",
    "\n",
    "# - per event, get relative time since start of case\n",
    "\n",
    "events['relativetime'] = events['timestamp'] - events['casestart']\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend event log with extra attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - per case, add attributes to event log:\n",
    "# (1) single string with sequence of activities (action_sequence)\n",
    "# (2) count total number of events (numactions)\n",
    "\n",
    "delimiter = '___'\n",
    "\n",
    "makeEventString = lambda x: delimiter.join(x)\n",
    "makeEventString.__name__ = 'makeEventString'\n",
    "\n",
    "numEvents = lambda x: len(x)\n",
    "numEvents.__name__ = 'numEvents'\n",
    "\n",
    "caselogs = events.pivot_table(index='patient', aggfunc={'action': [makeEventString, numEvents]})\n",
    "caselogs = caselogs.reset_index()\n",
    "caselogs.columns = ['patient', 'action_sequence', 'numactions']\n",
    "\n",
    "events = pd.merge(events, caselogs, on='patient')\n",
    "events['caselength'] = events['caseend'] - events['casestart']\n",
    "\n",
    "events.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - per event, add weekday, date & hour of timestamp; date of start-time; seconds & days of relative time\n",
    "\n",
    "events['weekday'] = events['timestamp'].apply(lambda x: x.weekday())\n",
    "events['date'] = events['timestamp'].apply(lambda x: x.date())\n",
    "events['hour'] = events['timestamp'].apply(lambda x: x.time().hour)\n",
    "events['startdate'] = events['casestart'].apply(lambda x: x.date())\n",
    "## Get relative times in more friendly terms\n",
    "events['relativetime_s'] = events['relativetime'].dt.seconds + 86400*events['relativetime'].dt.days\n",
    "events['relativedays'] = events['relativetime'].dt.days\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Ask some questions about the dataeset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the minimum number of events per case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Minimum number of events per case**: {}'.format(min(events['patient'].value_counts())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient 26\n",
    "* Which doctor did they have their first & last consultation with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_doctor = events[events['timestamp']==min(events[events['patient']=='patient 26']['timestamp'])]['resource'].values[0]\n",
    "last_doctor = events[events['timestamp']==max(events[events['patient']=='patient 26']['timestamp'])]['resource'].values[0]\n",
    "printmd('**First doctor**: {}'.format(first_doctor))\n",
    "printmd('**Last doctor**: {}'.format(last_doctor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which activity has the lowest occurrence overall in the event log?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Activity with lowest occurrence**: {}'.format(events['action'].value_counts().sort_values().idxmin()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - select all events belonging to first 50 patients\n",
    "\n",
    "patients = events['patient'].unique()\n",
    "selected_patients = patients[0:50]\n",
    "patientX = events[events['patient'].isin(selected_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - prepare some lists for visualization\n",
    "\n",
    "# per event, get patient case ids (used to setup Y axis ticks)\n",
    "patientnums = [int(e) for e in events['patient'].apply(lambda x: x.strip('patient'))]\n",
    "# per event, get ordinal for resource (used in later code)\n",
    "resourcenums = [i for (i, e) in enumerate(events['resource'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - plot resource usage over time\n",
    "\n",
    "ax = sns.scatterplot(x=events['timestamp'], y=events['resource'], hue=events['action'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative time \n",
    "Time since start of case.\n",
    "\n",
    "* y-axis represents each patient case.\n",
    "* x-axis represents time since case was initiated.\n",
    "* Different marker colors represent different actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - per patient case, time in days per activity\n",
    "\n",
    "ax = sns.scatterplot(x=events['relativedays'], y=events['patient'], hue=events['action'])\n",
    "plt.yticks(np.arange(min(patientnums), max(patientnums)+1, 5));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - sort events by case length and relative time to start\n",
    "\n",
    "ordered = events.sort_values(by=['caselength', 'relativedays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# - now, per patient case, time in days per activity (sorted events)\n",
    "\n",
    "ax = sns.scatterplot(x=ordered['relativedays'], y=ordered['patient'], hue=ordered['action'])\n",
    "plt.yticks(np.arange(min(patientnums), max(patientnums)+1, 5));\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get case data per patient (interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (widget libraries)\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "patients = events['patient'].unique()\n",
    "\n",
    "@interact\n",
    "def getCaseData(x=patients):\n",
    "    return events[events['patient']==x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting events that are (not) common to all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequency table (rows = patient cases; columns = actions; values = number of times action occurs for case)\n",
    "patient_events = pd.crosstab(events['patient'], events['action'])\n",
    "\n",
    "# create heat map\n",
    "sns.heatmap(patient_events, cmap=\"YlGnBu\")\n",
    "\n",
    "# per column (action), get number of unique values\n",
    "nunique = patient_events.apply(pd.Series.nunique)\n",
    "\n",
    "common_actions = nunique[nunique==1].index # (means only 1's are found)\n",
    "uncommon_actions = nunique[nunique>1].index # (means both 0's and 1's are found)\n",
    "printmd('**The following actions are common to all cases**: {}'.format(', '.join(common_actions)))\n",
    "printmd('**The following actions are not common to all cases**: {}'.format(', '.join(uncommon_actions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter events to only include uncommon events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = events[events['action'].isin(uncommon_actions)]\n",
    "patient_events = pd.crosstab(filtered['patient'], filtered['action'])\n",
    "\n",
    "printmd('**The filtered data has** {} **rows and** {} **columns.**'.format(filtered.shape[0], filtered.shape[1]))\n",
    "printmd('**This amounts to** {} **cases with** {} **distinct actions.**'.format(patient_events.shape[0], patient_events.shape[1]))\n",
    "\n",
    "# minus x-ray scans?\n",
    "filtered = filtered[filtered['action']!='X-ray scan']\n",
    "printmd('**The filtered data excluding X-rays has** {} **rows and** {} **columns.**'.format(filtered.shape[0], filtered.shape[1]))\n",
    "\n",
    "# filtered heat map\n",
    "sns.heatmap(patient_events, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Mining\n",
    "* Check out this [introduction to process mining in Python](https://towardsdatascience.com/introduction-to-process-mining-5f4ce985b7e5).\n",
    "* [Documentation for pm4py](https://pm4py.fit.fraunhofer.de/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the following in terminal:\n",
    "# %> pip install pm4py\n",
    "\n",
    "import pm4py\n",
    "\n",
    "# converters\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "\n",
    "# process mining \n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "from pm4py.algo.filtering.dfg.dfg_filtering import clean_dfg_based_on_noise_thresh\n",
    "\n",
    "# social network analysis\n",
    "from pm4py.algo.organizational_mining.sna import algorithm as sna_algorithm\n",
    "from pm4py.visualization.sna import visualizer as pn_vis\n",
    "\n",
    "# visualization\n",
    "# (wvw: updated, courtesy https://stackoverflow.com/questions/75424412/no-module-named-pm4py-objects-petri-in-pm4py)\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "# (wvw: added)\n",
    "from pm4py.visualization.dfg import visualizer as dfg_visualizer\n",
    "from pm4py.visualization.heuristics_net import visualizer as hn_visualizer\n",
    "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "\n",
    "# misc \n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "from pm4py.visualization.petri_net.util import performance_map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog = events.copy()\n",
    "\n",
    "# rename columns in accordance with pm4py\n",
    "# specify columns corresponding to case (case:concept:name), event (concept:name) & timestamp (time:timestamp)\n",
    "\n",
    "eventlog.rename(columns={'timestamp': 'time:timestamp', 'patient': 'case:concept:name', 'action': 'concept:name', 'resource': 'org:resource'}, inplace=True)\n",
    "\n",
    "# convert to log format\n",
    "log = log_converter.apply(eventlog)\n",
    "\n",
    "eventlog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process mining algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly-follows graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph from log\n",
    "dfg = dfg_discovery.apply(log, variant=dfg_discovery.Variants.PERFORMANCE)\n",
    "\n",
    "# visualize performance (durations)\n",
    "gviz = dfg_visualizer.apply(dfg, log=log, variant=dfg_visualizer.Variants.PERFORMANCE)\n",
    "dfg_visualizer.view(gviz)\n",
    "\n",
    "# admire the spaghetti ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With average times between nodes (performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph from log\n",
    "dfg = dfg_discovery.apply(log, variant=dfg_discovery.Variants.FREQUENCY)\n",
    "\n",
    "# visualize performance (frequency)\n",
    "\n",
    "gviz = dfg_visualizer.apply(dfg, log=log, variant=dfg_visualizer.Variants.FREQUENCY)\n",
    "dfg_visualizer.view(gviz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha miner\n",
    "net, initial_marking, final_marking = alpha_miner.apply(log)\n",
    "\n",
    "# visualise\n",
    "gviz = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "pn_visualizer.view(gviz)\n",
    "\n",
    "# better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add frequency to visualization\n",
    "gviz = pn_visualizer.apply(net, initial_marking, final_marking, \n",
    "                           variant=pn_visualizer.Variants.FREQUENCY, \n",
    "                           log=log)\n",
    "\n",
    "pn_visualizer.view(gviz)\n",
    "\n",
    "# (save the Petri net)\n",
    "# pn_visualizer.save(gviz, \"alpha_miner_healthcare_petri_net.png\")\n",
    "\n",
    "\n",
    "# compare with heat map with uncommon events:\n",
    "# (medicine is slightly less \"popular\" than x-rays, and surgery is least popular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heuristics miner\n",
    "heu_net = heuristics_miner.apply_heu(log)\n",
    "\n",
    "# visualize\n",
    "gviz = hn_visualizer.apply(heu_net)\n",
    "hn_visualizer.view(gviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show petri net (same output as alpha miner), incl. frequencies\n",
    "\n",
    "# heuristics miner\n",
    "net, im, fm = heuristics_miner.apply(log)\n",
    "\n",
    "# visualize\n",
    "gviz = pn_visualizer.apply(net, im, fm, \n",
    "                           variant=pn_visualizer.Variants.FREQUENCY, \n",
    "                           log=log)\n",
    "pn_visualizer.view(gviz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inductive miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the process tree\n",
    "# (wvw: drop \"_tree\" from call)\n",
    "tree = inductive_miner.apply(log)\n",
    "\n",
    "# visualize\n",
    "gviz = pt_visualizer.apply(tree)\n",
    "pt_visualizer.view(gviz)\n",
    "\n",
    "# creates a process treee instead of petri net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show petri net, incl. frequencies\n",
    "\n",
    "# (wvw - only process tree mining seems to be supported currently)\n",
    "\n",
    "# convert the process tree to a petri net\n",
    "net, initial_marking, final_marking = pt_converter.apply(tree)\n",
    "\n",
    "\n",
    "# (wvw: not working for me)\n",
    "# alternatively, use the inductive_miner to create a petri net from scratch\n",
    "# net, initial_marking, final_marking = inductive_miner.apply(log)\n",
    "\n",
    "# viz\n",
    "# parameters = {pn_visualizer.Variants.FREQUENCY.value.Parameters.FORMAT: \"png\"}\n",
    "gviz = pn_visualizer.apply(net, initial_marking, final_marking, \n",
    "                        #    parameters=parameters, \n",
    "                           variant=pn_visualizer.Variants.FREQUENCY, \n",
    "                           log=log)\n",
    "pn_visualizer.view(gviz)\n",
    "\n",
    "# pn_visualizer.save(gviz, \"inductive_miner_healthcare_petri_net.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variants\n",
    "\n",
    "Get unique process variants, i.e., unique sequences of activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pm4py.get_variants(log)\n",
    "variants = pd.DataFrame(variants.items())\n",
    "\n",
    "variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Networks\n",
    "\n",
    "* See [this guide](https://pm4py.fit.fraunhofer.de/documentation#social-network-analysis) on using pm4py to analyse social networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# different types of social interactions\n",
    "hw_values = sna_algorithm.apply(log, variant=sna_algorithm.Variants.HANDOVER_LOG)\n",
    "wt_values = sna_algorithm.apply(log, variant=sna_algorithm.Variants.WORKING_TOGETHER_LOG)\n",
    "sub_values = sna_algorithm.apply(log, variant=sna_algorithm.Variants.SUBCONTRACTING_LOG)\n",
    "ja_values = sna_algorithm.apply(log, variant=sna_algorithm.Variants.JOINTACTIVITIES_LOG)\n",
    "\n",
    "gviz_hw = pn_vis.apply(hw_values, variant=pn_vis.Variants.NETWORKX,\n",
    "                       parameters={pn_vis.Variants.NETWORKX.value.Parameters.FORMAT: \"png\"})\n",
    "gviz_wt = pn_vis.apply(wt_values, variant=pn_vis.Variants.NETWORKX,\n",
    "                       parameters={pn_vis.Variants.NETWORKX.value.Parameters.FORMAT: \"png\"})\n",
    "gviz_sub = pn_vis.apply(sub_values, variant=pn_vis.Variants.NETWORKX,\n",
    "                        parameters={pn_vis.Variants.NETWORKX.value.Parameters.FORMAT: \"png\"})\n",
    "gviz_ja = pn_vis.apply(ja_values, variant=pn_vis.Variants.NETWORKX,\n",
    "                       parameters={pn_vis.Variants.NETWORKX.value.Parameters.FORMAT: \"png\"})\n",
    "\n",
    "pn_vis.view(gviz_hw, variant=pn_vis.Variants.NETWORKX)\n",
    "pn_vis.view(gviz_wt, variant=pn_vis.Variants.NETWORKX)\n",
    "pn_vis.view(gviz_sub, variant=pn_vis.Variants.NETWORKX)\n",
    "pn_vis.view(gviz_ja, variant=pn_vis.Variants.NETWORKX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra material\n",
    "\n",
    "I did not find the code below very useful, including it here for completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple scatter plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=events['timestamp'], y=events['patient'], hue=events['action'])\n",
    "plt.yticks(np.arange(min(patientnums), max(patientnums)+1, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - per resource, time in days per activity (sorted events)\n",
    "\n",
    "ax = sns.scatterplot(x=ordered['relativedays'], y=ordered['resource'], hue=ordered['action'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(events['action'], events['resource'], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple stripplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Y axis = patient ordinal; X axis = weekday; dots = action\n",
    "\n",
    "ax = sns.stripplot(x=events['weekday'], y=patientnums, hue=events['action'], jitter=0.2)\n",
    "#plt.yticks(np.arange(min(patientnums), max(patientnums)+1, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Y axis = resource ordinal; X axis = weekday; dots = action\n",
    "\n",
    "ax = sns.stripplot(x=events['weekday'], y=resourcenums, hue=events['action'], jitter=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Y axis = patient ordinal; X axis = hour; dots = action\n",
    "\n",
    "ax = sns.stripplot(x=events['hour'], y=patientnums, hue=events['action'], jitter=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# - Y axis = resource ordinal; X axis = hour; dots = action\n",
    "\n",
    "ax = sns.stripplot(x=events['hour'], y=resourcenums, hue=events['action'], jitter=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - use unique markers per activity\n",
    "\n",
    "activities = list(events['action'].unique())\n",
    "markers = ['*', '+', 'h', 'o', 'x', 'D', '^', 'v']\n",
    "\n",
    "# (same # of markers as # of activities)\n",
    "assert(len(activities)==len(markers))\n",
    "\n",
    "def getEventPlot(patientlist=[patients[10], patients[21]]):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    \n",
    "    for x in patientlist:\n",
    "        patientX = getCaseData(x)\n",
    "        \n",
    "    \n",
    "        for i in range(0, len(activities)):\n",
    "            a = activities[i]\n",
    "            marker = markers[i]\n",
    "            selected = patientX[patientX['action']==a]\n",
    "            ax.plot(selected['relativetime_s'], \n",
    "                selected['patient'],\n",
    "                marker=marker, markersize=11,\n",
    "                alpha=0.9, color='blue', linewidth=0, \n",
    "                label=a);\n",
    "    plt.show()\n",
    "\n",
    "getEventPlot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
